<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="AI Voice Call Interface - Speak to register your complaint">
    <title>AI Voice Call | Vadodara Nagar Samwad</title>
    <link rel="stylesheet" href="css/style.css">
    <link rel="stylesheet" href="css/landing.css">
    <link rel="icon"
        href="data:image/svg+xml,<svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 100 100'><text y='.9em' font-size='90'>ğŸ¤</text></svg>">
</head>

<body>
    <!-- Top Navigation -->
    <nav class="top-nav">
        <a href="index.html" class="nav-brand">
            <span class="emblem">ğŸ›ï¸</span>
            <div class="nav-brand-text">
                <span class="title">Vadodara Nagar Samwad</span>
                <span class="subtitle">à¤µà¤¡à¥‹à¤¦à¤°à¤¾ à¤¨à¤—à¤° à¤¸à¤‚à¤µà¤¾à¤¦ | àªµàª¡à«‹àª¦àª°àª¾ àª¨àª—àª° àª¸àª‚àªµàª¾àª¦</span>
            </div>
        </a>
        <div class="nav-links">
            <a href="index.html" class="nav-link">Home</a>
            <a href="complaint.html" class="nav-link">Register Complaint</a>
            <a href="call.html" class="nav-link active">Voice Call</a>
            <a href="dashboard.html" class="nav-link">Dashboard</a>
            <a href="call.html" class="btn btn-primary" style="padding: 0.5rem 1rem; font-size: 0.9rem;">
                Start AI Call
            </a>
        </div>
    </nav>

    <div class="call-container">
        <header class="call-header">
            <h1>ğŸ¤ AI Voice Call Center</h1>
            <p>Speak naturally to register your complaint or request service</p>
        </header>

        <main class="call-main">
            <div class="call-controls">
                <div class="language-selector glass-card">
                    <label for="language">ğŸŒ Select Language:</label>
                    <select id="language" class="language-dropdown form-select">
                        <option value="en-US">English</option>
                        <option value="hi-IN">à¤¹à¤¿à¤‚à¤¦à¥€ (Hindi)</option>
                        <option value="gu-IN">àª—à«àªœàª°àª¾àª¤à«€ (Gujarati)</option>
                    </select>
                </div>
            </div>

            <div class="call-interface glass-card">
                <div class="microphone-section">
                    <button id="micButton" class="mic-button">
                        <span class="mic-icon">ğŸ¤</span>
                        <span class="mic-text">Start Listening</span>
                    </button>

                    <div class="voice-animation" id="voiceAnimation" style="display: none;">
                        <div class="wave"></div>
                        <div class="wave"></div>
                        <div class="wave"></div>
                        <div class="wave"></div>
                        <div class="wave"></div>
                    </div>

                    <p style="color: var(--text-muted); font-size: 0.9rem; margin-top: var(--space-md);">
                        Click the microphone button and speak your complaint
                    </p>
                </div>

                <div class="response-section">
                    <label for="aiResponse">ğŸ¤– AI Assistant:</label>
                    <textarea id="aiResponse" class="ai-response-box" readonly
                        placeholder="Welcome to AI Smart Call Center! Click the microphone button and describe your complaint. I'll guide you through the process..."></textarea>
                </div>

                <div class="user-input-section">
                    <label for="userInput">ğŸ“ Your Input:</label>
                    <textarea id="userInput" class="user-input-box"
                        placeholder="Your speech will be converted to text here. You can also type manually..."></textarea>
                </div>

                <div class="action-buttons">
                    <button id="submitButton" class="btn btn-primary">
                        âœ“ Submit
                    </button>
                    <button id="clearButton" class="btn btn-secondary">
                        â†º Clear
                    </button>
                    <a href="index.html" class="btn btn-secondary">
                        â† Go Back
                    </a>
                </div>
            </div>

            <div class="status-indicator glass-card">
                <p id="statusText" class="status-text">Ready to listen...</p>
            </div>

            <!-- Quick Actions -->
            <div style="text-align: center; margin-top: var(--space-xl);">
                <p style="color: var(--text-muted); margin-bottom: var(--space-md);">Or choose a complaint type
                    directly:</p>
                <div style="display: flex; flex-wrap: wrap; justify-content: center; gap: var(--space-sm);">
                    <a href="complaint.html" class="btn btn-secondary"
                        style="padding: 0.75rem 1.25rem; font-size: 0.9rem;">
                        ğŸ“‹ Select Complaint Type
                    </a>
                </div>
            </div>
        </main>

        <footer class="call-footer">
            <p>Vadodara Nagar Samwad Â© 2026 | Municipal Corporation</p>
        </footer>
    </div>

    <script src="js/config.js"></script>
    <script src="js/state.js"></script>
    <script src="js/speech.js"></script>
    <script src="js/flow.js"></script>
    <script src="js/api.js"></script>
    <script src="js/ui.js"></script>
    <script>
        // ===== IMPORTANT: Set up callbacks FIRST before any other code =====
        // This must be at the top to ensure callbacks are ready when speech.js needs them

        // Define the transcript update callback globally
        window.onFlowTranscriptUpdate = function (finalTranscript, interimTranscript) {
            const userInput = document.getElementById('userInput');
            if (userInput) {
                userInput.value = finalTranscript + interimTranscript;
            }
            console.log('[VOICE] Transcript update:', finalTranscript, interimTranscript);
        };

        // Also set window.onTranscriptUpdate as backup
        window.onTranscriptUpdate = function (finalTranscript, interimTranscript) {
            const userInput = document.getElementById('userInput');
            if (userInput) {
                userInput.value = finalTranscript + interimTranscript;
            }
            console.log('[VOICE] Transcript (backup):', finalTranscript, interimTranscript);
        };

        // ===== Main page functionality =====
        document.addEventListener('DOMContentLoaded', async function () {
            console.log('[VOICE] Page loaded, initializing...');

            const micButton = document.getElementById('micButton');
            const voiceAnimation = document.getElementById('voiceAnimation');
            const statusText = document.getElementById('statusText');
            const userInput = document.getElementById('userInput');
            const aiResponse = document.getElementById('aiResponse');
            const languageSelect = document.getElementById('language');
            const submitButton = document.getElementById('submitButton');
            const clearButton = document.getElementById('clearButton');

            let isListening = false;
            let micPermissionGranted = false;

            // Check browser support first
            const support = checkSpeechSupport();
            console.log('[VOICE] Browser support:', support);

            if (!support.speechRecognition) {
                statusText.textContent = 'âš ï¸ Speech recognition not supported. Please use Chrome or Edge browser.';
                micButton.disabled = true;
                micButton.style.opacity = '0.5';
                showToast('Speech recognition requires Chrome or Edge browser', 'error');
                return;
            }

            // Request microphone permission on page load
            statusText.textContent = 'ğŸ” Requesting microphone permission...';
            try {
                micPermissionGranted = await requestMicrophonePermission();
                if (micPermissionGranted) {
                    statusText.textContent = 'âœ… Microphone ready. Click the button to start speaking.';
                    console.log('[VOICE] Microphone permission granted');
                } else {
                    statusText.textContent = 'âŒ Microphone permission denied. Please allow microphone access.';
                    showToast('Please allow microphone access to use voice features', 'error');
                }
            } catch (error) {
                console.error('[VOICE] Microphone permission error:', error);
                statusText.textContent = 'âš ï¸ Could not access microphone. Click button to try again.';
            }

            // Update language when changed
            languageSelect.addEventListener('change', function () {
                const selectedLang = this.value;
                if (typeof setLanguage === 'function') setLanguage(selectedLang);
                if (typeof setRecognitionLanguage === 'function') setRecognitionLanguage(selectedLang);

                const langNames = {
                    'en-US': 'English',
                    'hi-IN': 'Hindi (à¤¹à¤¿à¤‚à¤¦à¥€)',
                    'gu-IN': 'Gujarati (àª—à«àªœàª°àª¾àª¤à«€)'
                };
                statusText.textContent = `ğŸŒ Language: ${langNames[selectedLang]}. Ready to listen...`;
                showToast(`Language changed to ${langNames[selectedLang]}`, 'success');
            });

            // Microphone button click handler
            micButton.addEventListener('click', async function () {
                console.log('[VOICE] Mic button clicked. isListening:', isListening);

                if (isListening) {
                    // Stop listening
                    if (typeof stopListening === 'function') {
                        stopListening();
                    }
                    micButton.classList.remove('listening');
                    micButton.querySelector('.mic-text').textContent = 'Start Listening';
                    voiceAnimation.style.display = 'none';
                    statusText.textContent = 'â¹ï¸ Stopped listening. Click to start again.';
                    isListening = false;
                    console.log('[VOICE] Stopped listening');
                } else {
                    // Request permission if not granted
                    if (!micPermissionGranted) {
                        statusText.textContent = 'ğŸ” Requesting microphone permission...';
                        try {
                            micPermissionGranted = await requestMicrophonePermission();
                        } catch (error) {
                            console.error('[VOICE] Permission error:', error);
                        }
                    }

                    // Start listening
                    console.log('[VOICE] Attempting to start listening...');
                    statusText.textContent = 'ğŸ¤ Starting...';

                    if (typeof startListening === 'function') {
                        const started = startListening(languageSelect.value);
                        console.log('[VOICE] startListening result:', started);

                        if (started) {
                            micButton.classList.add('listening');
                            micButton.querySelector('.mic-text').textContent = 'Stop';
                            voiceAnimation.style.display = 'flex';
                            statusText.textContent = 'ğŸ¤ Listening... Speak now!';
                            isListening = true;
                            showToast('Started listening. Speak your complaint.', 'success');
                        } else {
                            statusText.textContent = 'âŒ Could not start. Check microphone permission.';
                            showToast('Could not start speech recognition. Make sure microphone is allowed.', 'error');
                        }
                    } else {
                        console.error('[VOICE] startListening function not found!');
                        statusText.textContent = 'âŒ Speech system not loaded. Refresh the page.';
                        showToast('Speech system error. Please refresh the page.', 'error');
                    }
                }
            });

            // Submit button handler
            submitButton.addEventListener('click', function () {
                const text = userInput.value.trim();

                if (!text) {
                    showToast('Please provide some input before submitting.', 'error');
                    return;
                }

                // Stop listening if active
                if (isListening && typeof stopListening === 'function') {
                    stopListening();
                    isListening = false;
                    micButton.classList.remove('listening');
                    voiceAnimation.style.display = 'none';
                }

                // Detect complaint type from text
                const detectedType = detectComplaintTypeFromText(text);

                if (detectedType) {
                    // Save to state and navigate
                    if (typeof setState === 'function') {
                        setState({
                            complaint: { type: detectedType },
                            userDetails: { description: text },
                            currentStep: 'address'
                        });
                    }

                    aiResponse.value = `âœ“ Detected complaint type: ${detectedType}\n\nğŸ”„ Processing...\n\nNavigating to address form...`;

                    // Trigger n8n webhook (if configured)
                    triggerN8nWebhook({
                        action: 'complaint_detected',
                        type: detectedType,
                        description: text,
                        timestamp: new Date().toISOString()
                    });

                    showToast(`Complaint type detected: ${detectedType}`, 'success');

                    setTimeout(() => {
                        window.location.href = 'address.html';
                    }, 1500);
                } else {
                    aiResponse.value = "I couldn't determine the complaint type. Please select from the options below.";

                    if (typeof setState === 'function') {
                        setState({
                            userDetails: { description: text }
                        });
                    }

                    showToast('Please select complaint type manually', 'info');

                    setTimeout(() => {
                        window.location.href = 'complaint.html';
                    }, 2000);
                }
            });

            // Clear button handler
            clearButton.addEventListener('click', function () {
                userInput.value = '';
                aiResponse.value = '';
                if (typeof clearTranscript === 'function') {
                    clearTranscript();
                }
                statusText.textContent = 'ğŸ”„ Cleared. Ready to listen...';
                showToast('Cleared', 'info');
            });

            // Local complaint type detection
            function detectComplaintTypeFromText(text) {
                const textLower = text.toLowerCase();

                const keywords = {
                    'Street Light': ['light', 'lamp', 'street light', 'pole', 'dark', 'bulb', 'electricity', 'lighting', 'not working light', 'à¤¬à¤¤à¥à¤¤à¥€', 'à¤¬à¤¿à¤œà¤²à¥€', 'àª²àª¾àª‡àªŸ'],
                    'Water Supply': ['water', 'supply', 'pipe', 'leakage', 'tap', 'plumbing', 'sewage', 'no water', 'à¤ªà¤¾à¤¨à¥€', 'à¤¨à¤²', 'àªªàª¾àª£à«€'],
                    'Road Damage': ['road', 'pothole', 'damage', 'crack', 'street', 'asphalt', 'pavement', 'broken road', 'à¤¸à¤¡à¤¼à¤•', 'à¤—à¤¡à¥à¤¢à¤¾', 'àª°àª¸à«àª¤à«‹'],
                    'Garbage': ['garbage', 'waste', 'trash', 'rubbish', 'cleanup', 'dustbin', 'dump', 'sanitation', 'dirty', 'à¤•à¤šà¤°à¤¾', 'à¤•à¥‚à¤¡à¤¼à¤¾', 'àª•àªšàª°à«‹'],
                    'Drainage': ['drain', 'drainage', 'gutter', 'sewer', 'à¤¨à¤¾à¤²à¥€', 'àª¡à«àª°à«‡àª¨à«‡àªœ']
                };

                let bestMatch = null;
                let maxScore = 0;

                for (const [type, words] of Object.entries(keywords)) {
                    let score = 0;
                    for (const word of words) {
                        if (textLower.includes(word)) {
                            score++;
                        }
                    }
                    if (score > maxScore) {
                        maxScore = score;
                        bestMatch = type;
                    }
                }

                return maxScore > 0 ? bestMatch : null;
            }

            // n8n Webhook Trigger
            function triggerN8nWebhook(data) {
                const n8nWebhookUrl = CONFIG.N8N?.WEBHOOK_URL || null;

                if (n8nWebhookUrl) {
                    fetch(n8nWebhookUrl, {
                        method: 'POST',
                        headers: {
                            'Content-Type': 'application/json'
                        },
                        body: JSON.stringify(data)
                    }).then(response => {
                        console.log('[N8N] Webhook triggered:', response);
                    }).catch(error => {
                        console.error('[N8N] Webhook error:', error);
                    });
                }
            }

            // Initial AI greeting
            aiResponse.value = "ğŸ¤– Welcome to AI Smart Call Center!\n\nğŸ’¬ Click the microphone button and describe your complaint. I'll help you register it quickly.\n\nâœï¸ You can also type your complaint directly in the input box below.\n\nğŸŒ Supports: English, Hindi, Gujarati";
        });

        // Toast notification function
        function showToast(message, type = 'info') {
            const existingToast = document.querySelector('.toast');
            if (existingToast) existingToast.remove();

            const toast = document.createElement('div');
            toast.className = `toast ${type}`;
            toast.innerHTML = `<span>${type === 'success' ? 'âœ“' : type === 'error' ? 'âœ—' : 'â„¹ï¸'}</span> ${message}`;
            document.body.appendChild(toast);

            setTimeout(() => {
                toast.style.opacity = '0';
                toast.style.transform = 'translateX(100px)';
                setTimeout(() => toast.remove(), 300);
            }, 3000);
        }
    </script>

    <style>
        .workflow-indicator {
            width: 10px;
            height: 10px;
            border-radius: 50%;
            background: var(--text-muted);
        }

        .workflow-indicator.active {
            background: var(--success-gradient);
            box-shadow: 0 0 10px rgba(56, 239, 125, 0.5);
            animation: workflowPulse 2s ease-in-out infinite;
        }

        @keyframes workflowPulse {

            0%,
            100% {
                transform: scale(1);
                opacity: 1;
            }

            50% {
                transform: scale(1.2);
                opacity: 0.7;
            }
        }
    </style>
</body>

</html>